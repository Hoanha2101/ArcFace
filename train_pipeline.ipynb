{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, ReLU, Dropout, MaxPool2d, Sequential, Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path data\n",
    "\n",
    "path_data = 'data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.listdir(path_data)\n",
    "num_classes = len(folder)\n",
    "print(\"Number of people:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (112,112)\n",
    "\n",
    "# refer to https://pytorch.org/docs/stable/torchvision/transforms.html for more build-in online data augmentation\n",
    "\n",
    "data_transform = transforms.Compose([ \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize([int(128 * INPUT_SIZE[0] / 112), int(128 * INPUT_SIZE[0] / 112)]), # smaller side resized\n",
    "        transforms.RandomCrop([INPUT_SIZE[0], INPUT_SIZE[1]]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder.sort()\n",
    "print(len(folder))\n",
    "\n",
    "for i in range(len(folder)):\n",
    "    path_singer = os.path.join(path_data, folder[i])\n",
    "    for j in os.listdir(path_singer):\n",
    "        path_img = os.path.join(path_singer, j)\n",
    "        img = cv2.imread(path_img)\n",
    "        img = cv2.resize(img, INPUT_SIZE)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of images:\", len(images))\n",
    "print(\"Number of labels:\", len(labels))\n",
    "print(f\"Shape of images array: {np.array(images).shape}\")\n",
    "print(f\"Shape of labels array: {np.array(labels).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Shuffle\n",
    "\n",
    "I have prepared a separate train and test set so there is no need to split it into train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle the training data\n",
    "X_train, y_train = shuffle(images, labels, random_state=42)\n",
    "\n",
    "print(\"Number of train image:\", len(X_train))\n",
    "print(\"Number of train label:\", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBasic(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = DataBasic(X_train, y_train, data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = os.cpu_count()\n",
    "\n",
    "train_loader = DataLoader(dataset = data_train,\n",
    "                         batch_size= 16,\n",
    "                         shuffle = False,\n",
    "                         num_workers = num_workers,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "x = next(iter(train_loader))\n",
    "img = x[0][2]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (112,112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backbone.model_irse import IR_SE_50\n",
    "BACKBONE = IR_SE_50(INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 512\n",
    "\n",
    "NUM_CLASS = len(np.unique(labels))\n",
    "print(f'NUM_CLASS : {NUM_CLASS}')\n",
    "\n",
    "GPU_ID = [0]\n",
    "\n",
    "# STAGES = [35, 65, 95]\n",
    "# LR = 0.1  # initial LR\n",
    "# WEIGHT_DECAY = 5e-4  # do not apply to batch_norm parameters\n",
    "# MOMENTUM = 0.9\n",
    "# BATCH_SIZE = 16\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.loss_ArcFace import ArcFace\n",
    "from loss.loss_Focal import FocalLoss\n",
    "from utils import separate_resnet_bn_paras, schedule_lr\n",
    "\n",
    "HEAD = ArcFace(in_features=EMBEDDING_SIZE, out_features=NUM_CLASS, device_id=GPU_ID)\n",
    "LOSS = FocalLoss()\n",
    "\n",
    "# Separate parameters\n",
    "backbone_paras_only_bn, backbone_paras_wo_bn = separate_resnet_bn_paras(BACKBONE)\n",
    "_, head_paras_wo_bn = separate_resnet_bn_paras(HEAD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Initialize optimizer\n",
    "LR = 0.0001\n",
    "\n",
    "OPTIMIZER = optim.Adam([{'params': backbone_paras_wo_bn + head_paras_wo_bn}, {'params': backbone_paras_only_bn}], lr=LR)\n",
    "\n",
    "# OPTIMIZER = optim.SGD([{'params': backbone_paras_wo_bn + head_paras_wo_bn, 'weight_decay': WEIGHT_DECAY}, {'params': backbone_paras_only_bn}], lr = LR, momentum = MOMENTUM)\n",
    "\n",
    "# # Initialize scheduler\n",
    "scheduler = StepLR(OPTIMIZER, step_size=65, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move models to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD = HEAD.to(DEVICE)\n",
    "BACKBONE = BACKBONE.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Save check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 300\n",
    "total_step = len(train_loader)\n",
    "print(f'total_step: {total_step}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "import time\n",
    "\n",
    "BACKBONE.train()  # Set to training mode\n",
    "HEAD.train()\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print('Epoch:', e + 1)\n",
    "    LOSSES = []\n",
    "    start = time.time()\n",
    "\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Forward pass\n",
    "        features = BACKBONE(images)\n",
    "        outputs = HEAD(features, labels)\n",
    "\n",
    "        loss = LOSS(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "        LOSSES.append(loss.item())\n",
    "\n",
    "    # if e == STAGES[0]: # adjust LR for each training stage after warm up, you can also choose to adjust LR manually (with slight modification) once plaueau observed\n",
    "    #     schedule_lr(OPTIMIZER)\n",
    "    # if e == STAGES[1]:\n",
    "    #     schedule_lr(OPTIMIZER)\n",
    "    # if e == STAGES[2]:\n",
    "    #     schedule_lr(OPTIMIZER)\n",
    "\n",
    "    # Adam\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_train = np.mean(LOSSES)\n",
    "    end = time.time()\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    if (e + 1) % 10 == 0:\n",
    "        BACKBONE_path = f'checkpoint/ISE_{e + 1}.pth'\n",
    "        torch.save(BACKBONE, BACKBONE_path)\n",
    "        print(f\"Saved {BACKBONE_path}\")\n",
    "\n",
    "    print(f'Train loss: {loss_train:.4f} Time: {end - start:.2f} s')\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
